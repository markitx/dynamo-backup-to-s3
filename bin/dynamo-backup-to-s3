#!/usr/bin/env node

var program = require('commander'),
    fs = require('fs'),
    moment = require('moment'),
    DynamoBackup = require('../');

// options

function list(val) {
  return val.split(',');
}

function parseBool(val) {
    return val == 'true';
}

program
    .version(JSON.parse(fs.readFileSync(__dirname + '/../package.json', 'utf8')).version)
    .usage('[options]')
    .option('-b, --bucket <name>', 'S3 bucket to store backups')
    .option('-s, --stop-on-failure', 'specify the reporter to use', parseBool, true)
    .option('-r, --read-percentage <decimal>', 'specific the percentage of Dynamo read capacity to use while backing up. default .25 (25%)', parseFloat, .25)
    .option('-c, --on-demand-read-capacity <integer>', 'the throughput for the client to use if the table is in ondemand mode', parseInt, 25)
    .option('-x, --excluded-tables <list>', 'exclude these tables from backup', list)
    .option('-i, --included-tables <list>', 'only backup these tables', list)
    .option('-p, --backup-path <name>', 'backup path to store table dumps in. default is DynamoDB-backup-YYYY-MM-DD-HH-mm-ss')
    .option('-e, --base64-encode-binary', 'encode binary fields in base64 before exporting')
    .option('-d, --save-data-pipeline-format', 'save in format compatible with the AWS Data Pipeline import. Default to false (save as exported by DynamoDb)')
    .option('--aws-key <key>', 'AWS access key. Will use AWS_ACCESS_KEY_ID env var if --aws-key not set')
    .option('--aws-secret <secret>', 'AWS secret key. Will use AWS_SECRET_ACCESS_KEY env var if --aws-secret not set')
    .option('--aws-session-token <token>', 'AWS session token - optional, use if working with temporary credentials. Will use AWS_SESSION_TOKEN env var if --aws-session-token not set')
    .option('--aws-region <region>', 'AWS region. Will use AWS_DEFAULT_REGION env var if --aws-region not set')
    .parse(process.argv);

// run program

var runTimes = {};

var dynamoBackup = new DynamoBackup({
    awsKey: program.awsKey,
    awsSecret: program.awsSecret,
    awsSessionToken: program.awsSessionToken,
    awsRegion: program.awsRegion,
    backupPath: program.backupPath,
    bucket: program.bucket,
    excludedTables: program.excludedTables,
    includedTables: program.includedTables,
    readPercentage: program.readPercentage,
    onDemandReadCapacity: program.onDemandReadCapacity,
    stopOnFailure: program.stopOnFailure,
    base64Binary: program.base64EncodeBinary,
    saveDataPipelineFormat: program.saveDataPipelineFormat
});

dynamoBackup.on('error', function(data) {
    console.log('Error backing up ' + data.tableName);
    console.log(data.error);
    if (program.stopOnFailure) {
        process.exit(-1);
    }
});

dynamoBackup.on('start-backup', function(tableName) {
    runTimes[tableName] = moment();
    console.log('Starting to copy table ' + tableName);
});

dynamoBackup.on('end-backup', function(tableName) {
    var endTime = moment();
    var startTime = runTimes[tableName];
    console.log('Done copying table ' + tableName + '. Took ' + endTime.diff(startTime, 'minutes', true).toFixed(2) + ' minutes');
});

dynamoBackup.backupAllTables(function(error) {
    if (error) {
      console.error('Error:', error.message);
      process.exit(1);
    }
    console.log('Finished backing up DynamoDB');
    process.exit(0);
});